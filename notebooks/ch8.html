
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Variants of Differential Privacy &#8212; Programming Differential Privacy</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The Exponential Mechanism" href="ch9.html" />
    <link rel="prev" title="Local Sensitivity" href="ch7.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Programming Differential Privacy</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="cover.html">
   Programming Differential Privacy
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch1.html">
   De-identification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch2.html">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Anonymity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch3.html">
   Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch4.html">
   Properties of Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch5.html">
   Sensitivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch6.html">
   Approximate Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch7.html">
   Local Sensitivity
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Variants of Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch9.html">
   The Exponential Mechanism
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch10.html">
   The Sparse Vector Technique
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch11.html">
   Exercises in Algorithm Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch12.html">
   Machine Learning
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch13.html">
   Local Differential Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch14.html">
   Synthetic Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bibliography.html">
   Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/ch8.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/notebooks/ch8.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#max-divergence-and-renyi-divergence">
   Max Divergence and Rényi Divergence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#renyi-differential-privacy">
   Rényi Differential Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#zero-concentrated-differential-privacy">
   Zero-Concentrated Differential Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#truncated-concentrated-differential-privacy">
   Truncated Concentrated Differential Privacy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#composition-under-variants-of-differential-privacy">
   Composition under Variants of Differential Privacy
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="variants-of-differential-privacy">
<h1>Variants of Differential Privacy<a class="headerlink" href="#variants-of-differential-privacy" title="Permalink to this headline">¶</a></h1>
<div class="admonition-learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>After reading this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Define Rényi differential privacy and zero-concentrated differential privacy</p></li>
<li><p>Describe the advantages of these variants over <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy</p></li>
<li><p>Convert privacy costs from these variants into <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy</p></li>
</ul>
</div>
<p>Recall that most of the bounds on privacy cost we have shown are <em>upper</em> bounds, but they sometimes represent very loose upper bounds - the true privacy cost is much less than the upper bound says. The primary motivation in developing new variants of differential privacy is to enable tighter bounds on privacy cost - especially for iterative algorithms - while maintaining privacy definitions which are useful in practice. For example, the catastrophic failure mode of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy is not desirable; the variants we’ll see in this section enable even tighter composition for some kinds of queries, while at the same time <em>eliminating</em> the catastropic failure mode.</p>
<p>Let’s take a quick look at the tools we have already seen; we’ll look first at sequential composition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. It turns out that sequential composition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy is <em>tight</em>. What does that mean? It means there’s a counterexample that would fail to satisfy any lower bound:</p>
<ul class="simple">
<li><p>A mechanism <span class="math notranslate nohighlight">\(F\)</span> exists which satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy</p></li>
<li><p>When composed <span class="math notranslate nohighlight">\(k\)</span> times, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(k\epsilon\)</span>-differential privacy</p></li>
<li><p>But <span class="math notranslate nohighlight">\(F\)</span> does <em>not</em> satisfy <span class="math notranslate nohighlight">\(c\epsilon\)</span>-differential privacy for any <span class="math notranslate nohighlight">\(c &lt; k\)</span></p></li>
</ul>
<p>A neat way to visualize this is to look at what happens to privacy cost when we “vectorize” a query: that is, we merge lots of queries into a single query which returns a vector of the individual answers. Because the answer is a vector, we can use the vector-valued Laplace mechanism just once, and avoid composition altogether. Below, we’ll graph how much noise is needed for <span class="math notranslate nohighlight">\(k\)</span> queries, first under sequential composition, and then using the “vectorized” form. In the sequential composition case, each query has a sensitivity of 1, so the scale of the noise for each one is <span class="math notranslate nohighlight">\(\frac{1}{\epsilon_i}\)</span>. If we want a total privacy cost of <span class="math notranslate nohighlight">\(\epsilon\)</span>, then the <span class="math notranslate nohighlight">\(\epsilon_i\)</span>s must add up to <span class="math notranslate nohighlight">\(\epsilon\)</span>, so <span class="math notranslate nohighlight">\(\epsilon_i = \frac{\epsilon}{k}\)</span>. This means that each query gets Laplace noise with scale <span class="math notranslate nohighlight">\(\frac{k}{\epsilon}\)</span>. In the “vectorized” case, there’s just one query, but it has an L1 sensitivity of <span class="math notranslate nohighlight">\(\sum_{i=1}^k 1 = k\)</span>, so the scale of the noise is <span class="math notranslate nohighlight">\(\frac{k}{\epsilon}\)</span> in this case too.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>

<span class="c1"># L1 sensitivity of each query: 1</span>
<span class="c1"># noise per query: 1/epsilon</span>
<span class="c1"># number of queries: k</span>
<span class="n">noises_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_seq</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>

<span class="c1"># number of queries: 1</span>
<span class="c1"># L1 sensitivity of each query: k</span>
<span class="c1"># noise per query: k / epsilon</span>
<span class="n">noises_l1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_l1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Vectorized&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Laplace Mechanism: Vectorized vs. Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Queries&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Scale of Noise&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_3_0.png" src="../_images/ch8_3_0.png" />
</div>
</div>
<p>The two lines overlap <em>completely</em>. This means that no matter how many queries we’re running, under <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy, we can’t do any better than sequential composition. That’s because sequential composition is just as good as vectorizing the query, and we can’t do any better than that.</p>
<p>What about <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy? The story is a little different there. In the sequential composition case, we can use advanced composition; we have to be a little careful to ensure that the total privacy cost is exactly <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>. Specifically, we set <span class="math notranslate nohighlight">\(\epsilon_i = \frac{\epsilon}{2 \sqrt{2k \log(1/\delta')}}\)</span>, <span class="math notranslate nohighlight">\(\delta_i = \frac{\delta}{2k}\)</span>, and <span class="math notranslate nohighlight">\(\delta' = \frac{\delta}{2}\)</span> (splitting <span class="math notranslate nohighlight">\(\delta\)</span> to go 50% towards the queries, and 50% towards advanced composition). By advanced composition, the total privacy cost for all <span class="math notranslate nohighlight">\(k\)</span> queries is <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>. The scale of the noise, by the Gaussian mechanism, is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-543fa2f9-694d-4d45-87cb-92b911e8ed65">
<span class="eqno">(21)<a class="headerlink" href="#equation-543fa2f9-694d-4d45-87cb-92b911e8ed65" title="Permalink to this equation">¶</a></span>\[\begin{align}
\sigma^2 =&amp; \frac{2 \log(\frac{1.25}{\delta_i})}{\epsilon_i^2}\\
 =&amp; \frac{16 k \log(\frac{1}{\delta'}) \log(\frac{1.25}{\delta_i})}{\epsilon^2}\\
 =&amp; \frac{16 k \log(\frac{2}{\delta}) \log(\frac{2.5 k}{\delta})}{\epsilon^2}\\
\end{align}\]</div>
<p>In the “vectorized” case, we have just one query, with an L2 sensitivity of <span class="math notranslate nohighlight">\(\sqrt{k}\)</span>. The scale of the noise, by the Gaussian mechanism, is <span class="math notranslate nohighlight">\(\sigma^2 = \frac{2 k \log(1.25/\delta)}{\epsilon^2}\)</span>.</p>
<p>What does this difference mean in practice? The two behave the same asymptotically in <span class="math notranslate nohighlight">\(k\)</span>, but have different constants, and the advanced composition case has an additional logarithmic factor in <span class="math notranslate nohighlight">\(\delta\)</span>. All this adds up to a much looser bound in the case of advanced composition. Let’s graph the two as we did before.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="c1"># L2 sensitivity of each query: 1</span>
<span class="c1"># number of queries: k</span>
<span class="n">noises_seq</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_seq</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>

<span class="c1"># number of queries: 1</span>
<span class="c1"># L2 sensitivity of each query: sqrt(k)</span>
<span class="n">noises_l1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gaussian Mechanism: Vectorized vs. Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Queries&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Scale of Noise&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_l1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Vectorized&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_5_0.png" src="../_images/ch8_5_0.png" />
</div>
</div>
<p>It’s not even close - the “vectorized” version grows <em>much</em> slower. What does this mean? We should be able to do <em>much</em> better for sequential composition!</p>
<div class="section" id="max-divergence-and-renyi-divergence">
<h2>Max Divergence and Rényi Divergence<a class="headerlink" href="#max-divergence-and-renyi-divergence" title="Permalink to this headline">¶</a></h2>
<p>It turns out that the definition of differential privacy can be stated directly in terms of something called <em>max divergence</em>. In statistics, a <a class="reference external" href="https://en.wikipedia.org/wiki/Divergence_(statistics)"><em>divergence</em></a> is a way of measuring the distance between two probability distributions - which is exactly what we want to do for differential privacy. The <em>max divergence</em> is the worst-case analog of the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a>, one of the most common such measures. The max divergence between two probability distributions <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> is defined to be:</p>
<div class="amsmath math notranslate nohighlight" id="equation-eb0acec2-932b-481d-abee-73675dbac8b1">
<span class="eqno">(22)<a class="headerlink" href="#equation-eb0acec2-932b-481d-abee-73675dbac8b1" title="Permalink to this equation">¶</a></span>\[\begin{align}
D_\infty(Y \Vert Z) = \max_{S \subseteq \text{Supp}(Y)} \Big[\log \frac{Pr[Y \in S]}{Pr[Z \in S]} \Big]
\end{align}\]</div>
<p>This already looks a lot like the condition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy! In particular, it turns out that <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy if:</p>
<div class="amsmath math notranslate nohighlight" id="equation-757260e5-d995-4477-938e-e36bca484e24">
<span class="eqno">(23)<a class="headerlink" href="#equation-757260e5-d995-4477-938e-e36bca484e24" title="Permalink to this equation">¶</a></span>\[\begin{align}
D_\infty(F(x) \Vert F(x') \leq \epsilon
\end{align}\]</div>
<p>An interesting direction for research in differential privacy is the exploration of alternative privacy definitions in terms of other divergences. Of these, the <a class="reference external" href="https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence">Rényi divergence</a> is particularly interesting, since it also (like max divergence) allows us to recover the original definition of differential privacy. The Rényi divergence of order <span class="math notranslate nohighlight">\(\alpha\)</span> between probability distributions <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(Q\)</span> is defined as (where <span class="math notranslate nohighlight">\(P(x)\)</span> denotes the probability density of <span class="math notranslate nohighlight">\(P\)</span> at point <span class="math notranslate nohighlight">\(x\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-edca0a23-a70c-4223-bffc-fb03f99fcc96">
<span class="eqno">(24)<a class="headerlink" href="#equation-edca0a23-a70c-4223-bffc-fb03f99fcc96" title="Permalink to this equation">¶</a></span>\[\begin{align}
D_\alpha(P \Vert Q) = \frac{1}{\alpha - 1} \log E_{x \sim Q} \Big(\frac{P(x)}{Q(x)}\Big)^\alpha
\end{align}\]</div>
<p>If we set <span class="math notranslate nohighlight">\(\alpha = \infty\)</span>, then we immediately recover the definition of <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy! The obvious question arises: what happens if we set <span class="math notranslate nohighlight">\(\alpha\)</span> to something else? As we’ll see, it’s possible to use the Rényi divergence to derive really interesting relaxations of differential privacy that allow better composition theorems while at the same time avoiding the possibility of “catastrophe” which is possible under <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy.</p>
</div>
<div class="section" id="renyi-differential-privacy">
<h2>Rényi Differential Privacy<a class="headerlink" href="#renyi-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>In 2017, Ilya Mironov proposed <a class="reference external" href="https://arxiv.org/abs/1702.07476">Rényi differential privacy (RDP)</a> <span id="id1">[<a class="reference internal" href="bibliography.html#id13"><span>10</span></a>]</span>. A randomized mechanism <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP if for all neighboring datasets <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span></p>
<div class="amsmath math notranslate nohighlight" id="equation-912e2da1-d6d2-4aac-a356-f257fd1907bc">
<span class="eqno">(25)<a class="headerlink" href="#equation-912e2da1-d6d2-4aac-a356-f257fd1907bc" title="Permalink to this equation">¶</a></span>\[\begin{align}
D_\alpha(F(x) \Vert F(x')) \leq \bar{\epsilon}
\end{align}\]</div>
<p>In other words, RDP requires that the Rényi divergence of order <span class="math notranslate nohighlight">\(\alpha\)</span> between <span class="math notranslate nohighlight">\(F(x)\)</span> and <span class="math notranslate nohighlight">\(F(x')\)</span> to be bounded by <span class="math notranslate nohighlight">\(\bar{\epsilon}\)</span>. Note that we’ll use <span class="math notranslate nohighlight">\(\bar{\epsilon}\)</span> to denote the <span class="math notranslate nohighlight">\(\epsilon\)</span> parameter of RDP, in order to distinguish it from the <span class="math notranslate nohighlight">\(\epsilon\)</span> in pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy and <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy.</p>
<p>A key property of Rényi differential privacy is that a mechanism which satisfies RDP also satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. Specifically, if <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP, then for <span class="math notranslate nohighlight">\(\delta &gt; 0\)</span>, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy for <span class="math notranslate nohighlight">\(\epsilon = \bar{\epsilon} + \frac{\log(1/\delta)}{\alpha - 1}\)</span>. The analyst is free to pick any value of <span class="math notranslate nohighlight">\(\delta\)</span>; a meaningful value (e.g. <span class="math notranslate nohighlight">\(\delta \leq \frac{1}{n^2}\)</span>) should be picked in practice.</p>
<p>The basic mechanism for achieving Rényi differential privacy is the Gaussian mechanism. Specifically, for a function <span class="math notranslate nohighlight">\(f : \mathcal{D} \rightarrow \mathbb{R}^k\)</span> with <span class="math notranslate nohighlight">\(L2\)</span> sensitivity <span class="math notranslate nohighlight">\(\Delta f\)</span>, the following mechanism satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP:</p>
<div class="amsmath math notranslate nohighlight" id="equation-02016b71-05af-4833-866f-3f0dd7977225">
<span class="eqno">(26)<a class="headerlink" href="#equation-02016b71-05af-4833-866f-3f0dd7977225" title="Permalink to this equation">¶</a></span>\[\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2) \text{ where } \sigma^2 = \frac{\Delta f^2 \alpha}{2\epsilon}
\end{align}\]</div>
<p>We can implement the Gaussian mechanism for Rényi differential privacy as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_mech_RDP_vec</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">sensitivity</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The major advantage of Rényi differential privacy is <em>tight composition</em> for the Gaussian mechanism - and this advantage in composition comes without the need for a special advanced composition theorem. The sequential composition theorem of Rényi differential privacy states that:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(F_1\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_1})\)</span>-RDP</p></li>
<li><p>And <span class="math notranslate nohighlight">\(F_2\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_2})\)</span>-RDP</p></li>
<li><p>Then their composition satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_1} + \bar{\epsilon_2})\)</span>-RDP</p></li>
</ul>
<p>Based on this sequential composition theorem, running an <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP mechanism <span class="math notranslate nohighlight">\(k\)</span> times results in <span class="math notranslate nohighlight">\((\alpha, k\bar{\epsilon})\)</span>-RDP. For a given level of noise (i.e. a given value for <span class="math notranslate nohighlight">\(\sigma^2\)</span>), bounding the privacy cost of repeated applications of the Gaussian mechanism using RDP’s sequential composition, and <em>then</em> converting to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy, will usually yield a <em>much</em> lower privacy cost than performing the composition directly in <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span> world (even with advanced composition).</p>
<p>As a result, the ideas behind Rényi differential privacy have been used to greatly improve the privacy cost accounting in a number of recent iterative algorithms, including Google’s <a class="reference external" href="https://github.com/tensorflow/privacy">differentially private version of Tensorflow</a>.</p>
<p>Finally, like other variants of differential privacy, RDP provides a post-processing property.</p>
</div>
<div class="section" id="zero-concentrated-differential-privacy">
<h2>Zero-Concentrated Differential Privacy<a class="headerlink" href="#zero-concentrated-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>In concurrent work released in 2016, Mark Bun and Thomas Steinke proposed <a class="reference external" href="https://arxiv.org/abs/1605.02065">zero-concentrated differential privacy (zCDP)</a> <span id="id2">[<a class="reference internal" href="bibliography.html#id14"><span>11</span></a>]</span>. Like RDP, zCDP is defined in terms of the Rényi divergence, but it includes only a single privacy parameter (<span class="math notranslate nohighlight">\(\rho\)</span>). A randomized mechanism <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP if for all neighboring datasets <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span>, and all <span class="math notranslate nohighlight">\(\alpha \in (1, \infty)\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d13d44e8-fe4e-4f79-a19a-212e880d3f3f">
<span class="eqno">(27)<a class="headerlink" href="#equation-d13d44e8-fe4e-4f79-a19a-212e880d3f3f" title="Permalink to this equation">¶</a></span>\[\begin{align}
D_\alpha (F(x) \Vert F(x')) \leq \rho\alpha
\end{align}\]</div>
<p>This is a stronger requirement than RDP, because it restricts the Rényi divergence of many orders; however, the bound becomes more relaxed as <span class="math notranslate nohighlight">\(\alpha\)</span> grows. Like RDP, zCDP can be converted to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy: if <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP, then for <span class="math notranslate nohighlight">\(\delta &gt; 0\)</span>, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy for <span class="math notranslate nohighlight">\(\epsilon = \rho + 2\sqrt{\rho \log(1/\delta)}\)</span>.</p>
<p>zCDP is also similar to RDP in that the Gaussian mechanism can be used as a basic mechanism. Specifically, for a function <span class="math notranslate nohighlight">\(f : \mathcal{D} \rightarrow \mathbb{R}^k\)</span> with <span class="math notranslate nohighlight">\(L2\)</span> sensitivity <span class="math notranslate nohighlight">\(\Delta f\)</span>, the following mechanism satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP:</p>
<div class="amsmath math notranslate nohighlight" id="equation-06764798-3de4-433f-b01a-57dff512453d">
<span class="eqno">(28)<a class="headerlink" href="#equation-06764798-3de4-433f-b01a-57dff512453d" title="Permalink to this equation">¶</a></span>\[\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2) \text{ where } \sigma^2 = \frac{\Delta f^2}{2\rho}
\end{align}\]</div>
<p>As with RDP, this mechanism is easy to implement:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_mech_zCDP_vec</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">sensitivity</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rho</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>In another similarity with RDP, zCDP’s sequential composition is also asymptotically tight for repeated applications of the Gaussian mechanism. It’s also very simple: the <span class="math notranslate nohighlight">\(\rho\)</span>s add up. Specifically:</p>
<p>Sequential composition:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(F_1\)</span> satisfies <span class="math notranslate nohighlight">\(\rho_1\)</span>-zCDP</p></li>
<li><p>And <span class="math notranslate nohighlight">\(F_2\)</span> satisfies <span class="math notranslate nohighlight">\(\rho_2\)</span>-zCDP</p></li>
<li><p>Then their composition satisfies <span class="math notranslate nohighlight">\(\rho_1+\rho_2\)</span>-zCDP</p></li>
</ul>
<p>Finally, zCDP also provides a post-processing property.</p>
</div>
<div class="section" id="truncated-concentrated-differential-privacy">
<h2>Truncated Concentrated Differential Privacy<a class="headerlink" href="#truncated-concentrated-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p><strong>Coming soon</strong> <span id="id3">[<a class="reference internal" href="bibliography.html#id12"><span>12</span></a>]</span></p>
</div>
<div class="section" id="composition-under-variants-of-differential-privacy">
<h2>Composition under Variants of Differential Privacy<a class="headerlink" href="#composition-under-variants-of-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>Which variant should we use, and when?</p>
<p>The recently-developed variants will yield <em>significantly</em> tighter bounds on privacy cost when:</p>
<ul class="simple">
<li><p>The Gaussian mechanism is used (especially on high-dimensional vectors)</p></li>
<li><p>The algorithm in question applies the mechanism many times (e.g. hundreds or thousands of times)</p></li>
</ul>
<p>To use RDP and zCDP, we typically implement an algorithm in terms of the variant we want to use, and then convert the total privacy cost of running the algorithm back to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy so that we can compare it to other algorithms.</p>
<p>To see the effect of this strategy, let’s imagine an algorithm that applies the Gaussian mechanism <span class="math notranslate nohighlight">\(k\)</span> times. We’ll fix values for <span class="math notranslate nohighlight">\(\sigma\)</span> (i.e. the amount of noise added with the Gaussian mechanism in each of the <span class="math notranslate nohighlight">\(k\)</span> iterations) and <span class="math notranslate nohighlight">\(\delta\)</span>, and then compare the final <span class="math notranslate nohighlight">\(\epsilon\)</span>s achieved for each variant.</p>
<p>We’ll see that composition under RDP and zCDP result in <em>smaller values of <span class="math notranslate nohighlight">\(\epsilon\)</span> for the same amount of noise added</em>. The algorithm is identical under all variants (i.e. it adds the same amount of noise in each case) - so this means that RDP and zCDP are providing <em>significantly tighter bounds on privacy cost</em> for the <em>same algorithm</em>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mf">200.0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">lap_eps</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">gauss_eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ys_gauss_adv</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">gauss_eps</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">rho</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ys_gauss_zcdp</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x</span><span class="o">*</span><span class="n">rho</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span><span class="o">*</span><span class="n">rho</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">rdp_eps</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ys_gauss_rdp</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x</span><span class="o">*</span><span class="n">rdp_eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">ys_moments</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span><span class="o">/</span><span class="n">sigma</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_adv</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+Adv. Comp.&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_zcdp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+zCDP&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_rdp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+RDP&quot;</span><span class="p">)</span>
<span class="c1">#plt.plot(xs, ys_moments, label=&quot;Moments Accountant&quot;)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Iterations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Epsilon&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_16_0.png" src="../_images/ch8_16_0.png" />
</div>
</div>
<p>The first thing to note is that using sequential composition under either zCDP or RDP is <em>much</em> better than using advanced composition with <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. When building iterative algorithms with the Gaussian mechanism, these variants should always be used.</p>
<p>The second thing to note is the difference between zCDP (in orange) and RDP (in green). The <span class="math notranslate nohighlight">\(\epsilon\)</span> for RDP grows linearly in <span class="math notranslate nohighlight">\(k\)</span>, because we have fixed a value for <span class="math notranslate nohighlight">\(\alpha\)</span>. The <span class="math notranslate nohighlight">\(\epsilon\)</span> for zCDP is sublinear in <span class="math notranslate nohighlight">\(k\)</span>, since zCDP effectively considers many <span class="math notranslate nohighlight">\(\alpha\)</span>s. The two lines touch at some value of <span class="math notranslate nohighlight">\(k\)</span>, depending on the <span class="math notranslate nohighlight">\(\alpha\)</span> chosen for RDP (for <span class="math notranslate nohighlight">\(\alpha = 20\)</span>, they touch at roughly <span class="math notranslate nohighlight">\(k=300\)</span>).</p>
<p>The practial effect of this difference is that <span class="math notranslate nohighlight">\(\alpha\)</span> must be chosen carefully when using RDP in order to bound privacy cost as tightly as possible. This is usually easy to do, since algorithms are usually parameterized by <span class="math notranslate nohighlight">\(\alpha\)</span>; as a result, we can simply test multiple values of <span class="math notranslate nohighlight">\(\alpha\)</span> to see which one results in the smallest corresponding <span class="math notranslate nohighlight">\(\epsilon\)</span>. Since this test is <em>independent</em> of the data (it depends mainly on the privacy parameters we pick, and the number of iterations we want to run), we can test as many values of <span class="math notranslate nohighlight">\(\alpha\)</span> as we want without paying additional privacy cost. We only need to test a small range of values for <span class="math notranslate nohighlight">\(\alpha\)</span> - typically in the range between 2 and 100 - to find a minimum. This is the approach taken in most practical implementations, including Google’s privacy-preserving version of Tensorflow.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="ch7.html" title="previous page">Local Sensitivity</a>
    <a class='right-next' id="next-link" href="ch9.html" title="next page">The Exponential Mechanism</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joseph P. Near and Chiké Abuah<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>