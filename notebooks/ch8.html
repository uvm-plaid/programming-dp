

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Variants of Differential Privacy &#8212; Programming Differential Privacy</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="The Exponential Mechanism" href="ch9.html" />
    <link rel="prev" title="Local Sensitivity" href="ch7.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">Programming Differential Privacy</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="intro.html">Introduction</a>
  </li>
  <li class="">
    <a href="ch1.html">De-identification</a>
  </li>
  <li class="">
    <a href="ch2.html">k-Anonymity</a>
  </li>
  <li class="">
    <a href="ch3.html">Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch4.html">Properties of Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch5.html">Sensitivity</a>
  </li>
  <li class="">
    <a href="ch6.html">Approximate Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch7.html">Local Sensitivity</a>
  </li>
  <li class="active">
    <a href="">Variants of Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch9.html">The Exponential Mechanism</a>
  </li>
  <li class="">
    <a href="ch10.html">The Sparse Vector Technique</a>
  </li>
  <li class="">
    <a href="ch11.html">Exercises in Algorithm Design</a>
  </li>
  <li class="">
    <a href="ch12.html">Machine Learning</a>
  </li>
  <li class="">
    <a href="ch13.html">Local Differential Privacy</a>
  </li>
  <li class="">
    <a href="ch14.html">Synthetic Data</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/ch8.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#max-divergence-and-renyi-divergence" class="nav-link">Max Divergence and Rényi Divergence</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#renyi-differential-privacy" class="nav-link">Rényi Differential Privacy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#zero-concentrated-differential-privacy" class="nav-link">Zero-Concentrated Differential Privacy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#truncated-concentrated-differential-privacy" class="nav-link">Truncated Concentrated Differential Privacy</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#composition-under-variants-of-differential-privacy" class="nav-link">Composition under Variants of Differential Privacy</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="variants-of-differential-privacy">
<h1>Variants of Differential Privacy<a class="headerlink" href="#variants-of-differential-privacy" title="Permalink to this headline">¶</a></h1>
<div class="admonition-learning-objectives admonition">
<p class="admonition-title">Learning Objectives</p>
<p>After reading this chapter, you will be able to:</p>
<ul class="simple">
<li><p>Define Rényi differential privacy and zero-concentrated differential privacy</p></li>
<li><p>Describe the advantages of these variants over <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy</p></li>
<li><p>Convert privacy costs from these variants into <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy</p></li>
</ul>
</div>
<p>Recall that most of the bounds on privacy cost we have shown are <em>upper</em> bounds, but they sometimes represent very loose upper bounds - the true privacy cost is much less than the upper bound says. The primary motivation in developing new variants of differential privacy is to enable tighter bounds on privacy cost - especially for iterative algorithms - while maintaining privacy definitions which are useful in practice. For example, the catastrophic failure mode of <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy is not desirable; the variants we’ll see in this section enable even tighter composition for some kinds of queries, while at the same time <em>eliminating</em> the catastropic failure mode.</p>
<p>Let’s take a quick look at the tools we have already seen; we’ll look first at sequential composition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy. It turns out that sequential composition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy is <em>tight</em>. What does that mean? It means there’s a counterexample that would fail to satisfy any lower bound:</p>
<ul class="simple">
<li><p>A mechanism <span class="math notranslate nohighlight">\(F\)</span> exists which satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy</p></li>
<li><p>When composed <span class="math notranslate nohighlight">\(k\)</span> times, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(k\epsilon\)</span>-differential privacy</p></li>
<li><p>But <span class="math notranslate nohighlight">\(F\)</span> does <em>not</em> satisfy <span class="math notranslate nohighlight">\(c\epsilon\)</span>-differential privacy for any <span class="math notranslate nohighlight">\(c &lt; k\)</span></p></li>
</ul>
<p>A neat way to visualize this is to look at what happens to privacy cost when we “vectorize” a query: that is, we merge lots of queries into a single query which returns a vector of the individual answers. Because the answer is a vector, we can use the vector-valued Laplace mechanism just once, and avoid composition altogether. Below, we’ll graph how much noise is needed for <span class="math notranslate nohighlight">\(k\)</span> queries, first under sequential composition, and then using the “vectorized” form. In the sequential composition case, each query has a sensitivity of 1, so the scale of the noise for each one is <span class="math notranslate nohighlight">\(\frac{1}{\epsilon_i}\)</span>. If we want a total privacy cost of <span class="math notranslate nohighlight">\(\epsilon\)</span>, then the <span class="math notranslate nohighlight">\(\epsilon_i\)</span>s must add up to <span class="math notranslate nohighlight">\(\epsilon\)</span>, so <span class="math notranslate nohighlight">\(\epsilon_i = \frac{\epsilon}{k}\)</span>. This means that each query gets Laplace noise with scale <span class="math notranslate nohighlight">\(\frac{k}{\epsilon}\)</span>. In the “vectorized” case, there’s just one query, but it has an L1 sensitivity of <span class="math notranslate nohighlight">\(\sum_{i=1}^k 1 = k\)</span>, so the scale of the noise is <span class="math notranslate nohighlight">\(\frac{k}{\epsilon}\)</span> in this case too.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>

<span class="c1"># L1 sensitivity of each query: 1</span>
<span class="c1"># noise per query: 1/epsilon</span>
<span class="c1"># number of queries: k</span>
<span class="n">noises_seq</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_seq</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sequential Composition&#39;</span><span class="p">)</span>

<span class="c1"># number of queries: 1</span>
<span class="c1"># L1 sensitivity of each query: k</span>
<span class="c1"># noise per query: k / epsilon</span>
<span class="n">noises_l1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">*</span><span class="p">(</span><span class="n">k</span><span class="o">/</span><span class="n">epsilon</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_l1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Vectorized&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Laplace Mechanism: Vectorized vs. Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Queries&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Scale of Noise&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_3_0.png" src="../_images/ch8_3_0.png" />
</div>
</div>
<p>The two lines overlap <em>completely</em>. This means that no matter how many queries we’re running, under <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy, we can’t do any better than sequential composition. That’s because sequential composition is just as good as vectorizing the query, and we can’t do any better than that.</p>
<p>What about <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy? The story is a little different there. In the sequential composition case, we can use advanced composition; we have to be a little careful to ensure that the total privacy cost is exactly <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>. Specifically, we set <span class="math notranslate nohighlight">\(\epsilon_i = \frac{\epsilon}{2 \sqrt{2k \log(1/\delta')}}\)</span>, <span class="math notranslate nohighlight">\(\delta_i = \frac{\delta}{2k}\)</span>, and <span class="math notranslate nohighlight">\(\delta' = \frac{\delta}{2}\)</span> (splitting <span class="math notranslate nohighlight">\(\delta\)</span> to go 50% towards the queries, and 50% towards advanced composition). By advanced composition, the total privacy cost for all <span class="math notranslate nohighlight">\(k\)</span> queries is <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>. The scale of the noise, by the Gaussian mechanism, is:</p>
<p>\begin{align}
\sigma^2 =&amp; \frac{2 \log(\frac{1.25}{\delta_i})}{\epsilon_i^2}\
=&amp; \frac{16 k \log(\frac{1}{\delta’}) \log(\frac{1.25}{\delta_i})}{\epsilon^2}\
=&amp; \frac{16 k \log(\frac{2}{\delta}) \log(\frac{2.5 k}{\delta})}{\epsilon^2}\
\end{align}</p>
<p>In the “vectorized” case, we have just one query, with an L2 sensitivity of <span class="math notranslate nohighlight">\(\sqrt{k}\)</span>. The scale of the noise, by the Gaussian mechanism, is <span class="math notranslate nohighlight">\(\sigma^2 = \frac{2 k \log(1.25/\delta)}{\epsilon^2}\)</span>.</p>
<p>What does this difference mean in practice? The two behave the same asymptotically in <span class="math notranslate nohighlight">\(k\)</span>, but have different constants, and the advanced composition case has an additional logarithmic factor in <span class="math notranslate nohighlight">\(\delta\)</span>. All this adds up to a much looser bound in the case of advanced composition. Let’s graph the two as we did before.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-5</span>

<span class="c1"># L2 sensitivity of each query: 1</span>
<span class="c1"># number of queries: k</span>
<span class="n">noises_seq</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_seq</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Advanced Composition&#39;</span><span class="p">)</span>

<span class="c1"># number of queries: 1</span>
<span class="c1"># L2 sensitivity of each query: sqrt(k)</span>
<span class="n">noises_l1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">k</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">epsilon</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ks</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gaussian Mechanism: Vectorized vs. Composition&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Queries&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Scale of Noise&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span> <span class="n">noises_l1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Vectorized&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_5_0.png" src="../_images/ch8_5_0.png" />
</div>
</div>
<p>It’s not even close - the “vectorized” version grows <em>much</em> slower. What does this mean? We should be able to do <em>much</em> better for sequential composition!</p>
<div class="section" id="max-divergence-and-renyi-divergence">
<h2>Max Divergence and Rényi Divergence<a class="headerlink" href="#max-divergence-and-renyi-divergence" title="Permalink to this headline">¶</a></h2>
<p>It turns out that the definition of differential privacy can be stated directly in terms of something called <em>max divergence</em>. In statistics, a <a class="reference external" href="https://en.wikipedia.org/wiki/Divergence_(statistics)"><em>divergence</em></a> is a way of measuring the distance between two probability distributions - which is exactly what we want to do for differential privacy. The <em>max divergence</em> is the worst-case analog of the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback–Leibler divergence</a>, one of the most common such measures. The max divergence between two probability distributions <span class="math notranslate nohighlight">\(Y\)</span> and <span class="math notranslate nohighlight">\(Z\)</span> is defined to be:</p>
<p>\begin{align}
D_\infty(Y \Vert Z) = \max_{S \subseteq \text{Supp}(Y)} \Big[\log \frac{Pr[Y \in S]}{Pr[Z \in S]} \Big]
\end{align}</p>
<p>This already looks a lot like the condition for <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy! In particular, it turns out that <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy if:</p>
<p>\begin{align}
D_\infty(F(x) \Vert F(x’) \leq \epsilon
\end{align}</p>
<p>An interesting direction for research in differential privacy is the exploration of alternative privacy definitions in terms of other divergences. Of these, the <a class="reference external" href="https://en.wikipedia.org/wiki/R%C3%A9nyi_entropy#R%C3%A9nyi_divergence">Rényi divergence</a> is particularly interesting, since it also (like max divergence) allows us to recover the original definition of differential privacy. The Rényi divergence of order <span class="math notranslate nohighlight">\(\alpha\)</span> between probability distributions <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(Q\)</span> is defined as (where <span class="math notranslate nohighlight">\(P(x)\)</span> denotes the probability density of <span class="math notranslate nohighlight">\(P\)</span> at point <span class="math notranslate nohighlight">\(x\)</span>):</p>
<p>\begin{align}
D_\alpha(P \Vert Q) = \frac{1}{\alpha - 1} \log E_{x \sim Q} \Big(\frac{P(x)}{Q(x)}\Big)^\alpha
\end{align}</p>
<p>If we set <span class="math notranslate nohighlight">\(\alpha = \infty\)</span>, then we immediately recover the definition of <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy! The obvious question arises: what happens if we set <span class="math notranslate nohighlight">\(\alpha\)</span> to something else? As we’ll see, it’s possible to use the Rényi divergence to derive really interesting relaxations of differential privacy that allow better composition theorems while at the same time avoiding the possibility of “catastrophe” which is possible under <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy.</p>
</div>
<div class="section" id="renyi-differential-privacy">
<h2>Rényi Differential Privacy<a class="headerlink" href="#renyi-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>In 2017, Ilya Mironov proposed <a class="reference external" href="https://arxiv.org/abs/1702.07476">Rényi differential privacy (RDP)</a>. A randomized mechanism <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP if for all neighboring datasets <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span></p>
<p>\begin{align}
D_\alpha(F(x) \Vert F(x’)) \leq \bar{\epsilon}
\end{align}</p>
<p>In other words, RDP requires that the Rényi divergence of order <span class="math notranslate nohighlight">\(\alpha\)</span> between <span class="math notranslate nohighlight">\(F(x)\)</span> and <span class="math notranslate nohighlight">\(F(x')\)</span> to be bounded by <span class="math notranslate nohighlight">\(\bar{\epsilon}\)</span>. Note that we’ll use <span class="math notranslate nohighlight">\(\bar{\epsilon}\)</span> to denote the <span class="math notranslate nohighlight">\(\epsilon\)</span> parameter of RDP, in order to distinguish it from the <span class="math notranslate nohighlight">\(\epsilon\)</span> in pure <span class="math notranslate nohighlight">\(\epsilon\)</span>-differential privacy and <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy.</p>
<p>A key property of Rényi differential privacy is that a mechanism which satisfies RDP also satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. Specifically, if <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP, then for <span class="math notranslate nohighlight">\(\delta &gt; 0\)</span>, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy for <span class="math notranslate nohighlight">\(\epsilon = \bar{\epsilon} + \frac{\log(1/\delta)}{\alpha - 1}\)</span>. The analyst is free to pick any value of <span class="math notranslate nohighlight">\(\delta\)</span>; a meaningful value (e.g. <span class="math notranslate nohighlight">\(\delta \leq \frac{1}{n^2}\)</span>) should be picked in practice.</p>
<p>The basic mechanism for achieving Rényi differential privacy is the Gaussian mechanism. Specifically, for a function <span class="math notranslate nohighlight">\(f : \mathcal{D} \rightarrow \mathbb{R}^k\)</span> with <span class="math notranslate nohighlight">\(L2\)</span> sensitivity <span class="math notranslate nohighlight">\(\Delta f\)</span>, the following mechanism satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP:</p>
<p>\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2) \text{ where } \sigma^2 = \frac{\Delta f^2 \alpha}{2\epsilon}
\end{align}</p>
<p>We can implement the Gaussian mechanism for Rényi differential privacy as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_mech_RDP_vec</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">):</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">sensitivity</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">epsilon</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>The major advantage of Rényi differential privacy is <em>tight composition</em> for the Gaussian mechanism - and this advantage in composition comes without the need for a special advanced composition theorem. The sequential composition theorem of Rényi differential privacy states that:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(F_1\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_1})\)</span>-RDP</p></li>
<li><p>And <span class="math notranslate nohighlight">\(F_2\)</span> satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_2})\)</span>-RDP</p></li>
<li><p>Then their composition satisfies <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon_1} + \bar{\epsilon_2})\)</span>-RDP</p></li>
</ul>
<p>Based on this sequential composition theorem, running an <span class="math notranslate nohighlight">\((\alpha, \bar{\epsilon})\)</span>-RDP mechanism <span class="math notranslate nohighlight">\(k\)</span> times results in <span class="math notranslate nohighlight">\((\alpha, k\bar{\epsilon})\)</span>-RDP. For a given level of noise (i.e. a given value for <span class="math notranslate nohighlight">\(\sigma^2\)</span>), bounding the privacy cost of repeated applications of the Gaussian mechanism using RDP’s sequential composition, and <em>then</em> converting to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy, will usually yield a <em>much</em> lower privacy cost than performing the composition directly in <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span> world (even with advanced composition).</p>
<p>As a result, the ideas behind Rényi differential privacy have been used to greatly improve the privacy cost accounting in a number of recent iterative algorithms, including Google’s <a class="reference external" href="https://github.com/tensorflow/privacy">differentially private version of Tensorflow</a>.</p>
<p>Finally, like other variants of differential privacy, RDP provides a post-processing property.</p>
</div>
<div class="section" id="zero-concentrated-differential-privacy">
<h2>Zero-Concentrated Differential Privacy<a class="headerlink" href="#zero-concentrated-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>In concurrent work released in 2016, Mark Bun and Thomas Steinke proposed <a class="reference external" href="https://arxiv.org/abs/1605.02065">zero-concentrated differential privacy (zCDP)</a>. Like RDP, zCDP is defined in terms of the Rényi divergence, but it includes only a single privacy parameter (<span class="math notranslate nohighlight">\(\rho\)</span>). A randomized mechanism <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP if for all neighboring datasets <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(x'\)</span>, and all <span class="math notranslate nohighlight">\(\alpha \in (1, \infty)\)</span>:</p>
<p>\begin{align}
D_\alpha (F(x) \Vert F(x’)) \leq \rho\alpha
\end{align}</p>
<p>This is a stronger requirement than RDP, because it restricts the Rényi divergence of many orders; however, the bound becomes more relaxed as <span class="math notranslate nohighlight">\(\alpha\)</span> grows. Like RDP, zCDP can be converted to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy: if <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP, then for <span class="math notranslate nohighlight">\(\delta &gt; 0\)</span>, <span class="math notranslate nohighlight">\(F\)</span> satisfies <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy for <span class="math notranslate nohighlight">\(\epsilon = \rho + 2\sqrt{\rho \log(1/\delta)}\)</span>.</p>
<p>zCDP is also similar to RDP in that the Gaussian mechanism can be used as a basic mechanism. Specifically, for a function <span class="math notranslate nohighlight">\(f : \mathcal{D} \rightarrow \mathbb{R}^k\)</span> with <span class="math notranslate nohighlight">\(L2\)</span> sensitivity <span class="math notranslate nohighlight">\(\Delta f\)</span>, the following mechanism satisfies <span class="math notranslate nohighlight">\(\rho\)</span>-zCDP:</p>
<p>\begin{align}
F(x) = f(x) + \mathcal{N}(\sigma^2) \text{ where } \sigma^2 = \frac{\Delta f^2}{2\rho}
\end{align}</p>
<p>As with RDP, this mechanism is easy to implement:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gaussian_mech_zCDP_vec</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">sensitivity</span><span class="p">,</span> <span class="n">rho</span><span class="p">):</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">sensitivity</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rho</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vec</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>In another similarity with RDP, zCDP’s sequential composition is also asymptotically tight for repeated applications of the Gaussian mechanism. It’s also very simple: the <span class="math notranslate nohighlight">\(\rho\)</span>s add up. Specifically:</p>
<p>Sequential composition:</p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(F_1\)</span> satisfies <span class="math notranslate nohighlight">\(\rho_1\)</span>-zCDP</p></li>
<li><p>And <span class="math notranslate nohighlight">\(F_2\)</span> satisfies <span class="math notranslate nohighlight">\(\rho_2\)</span>-zCDP</p></li>
<li><p>Then their composition satisfies <span class="math notranslate nohighlight">\(\rho_1+\rho_2\)</span>-zCDP</p></li>
</ul>
<p>Finally, zCDP also provides a post-processing property.</p>
</div>
<div class="section" id="truncated-concentrated-differential-privacy">
<h2>Truncated Concentrated Differential Privacy<a class="headerlink" href="#truncated-concentrated-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p><strong>Coming soon</strong></p>
</div>
<div class="section" id="composition-under-variants-of-differential-privacy">
<h2>Composition under Variants of Differential Privacy<a class="headerlink" href="#composition-under-variants-of-differential-privacy" title="Permalink to this headline">¶</a></h2>
<p>Which variant should we use, and when?</p>
<p>The recently-developed variants will yield <em>significantly</em> tighter bounds on privacy cost when:</p>
<ul class="simple">
<li><p>The Gaussian mechanism is used (especially on high-dimensional vectors)</p></li>
<li><p>The algorithm in question applies the mechanism many times (e.g. hundreds or thousands of times)</p></li>
</ul>
<p>To use RDP and zCDP, we typically implement an algorithm in terms of the variant we want to use, and then convert the total privacy cost of running the algorithm back to <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy so that we can compare it to other algorithms.</p>
<p>To see the effect of this strategy, let’s imagine an algorithm that applies the Gaussian mechanism <span class="math notranslate nohighlight">\(k\)</span> times. We’ll fix values for <span class="math notranslate nohighlight">\(\sigma\)</span> (i.e. the amount of noise added with the Gaussian mechanism in each of the <span class="math notranslate nohighlight">\(k\)</span> iterations) and <span class="math notranslate nohighlight">\(\delta\)</span>, and then compare the final <span class="math notranslate nohighlight">\(\epsilon\)</span>s achieved for each variant.</p>
<p>We’ll see that composition under RDP and zCDP result in <em>smaller values of <span class="math notranslate nohighlight">\(\epsilon\)</span> for the same amount of noise added</em>. The algorithm is identical under all variants (i.e. it adds the same amount of noise in each case) - so this means that RDP and zCDP are providing <em>significantly tighter bounds on privacy cost</em> for the <em>same algorithm</em>.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mf">200.0</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">1e-5</span>
<span class="n">lap_eps</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="n">gauss_eps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1.25</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span> <span class="o">/</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ys_gauss_adv</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">gauss_eps</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">rho</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ys_gauss_zcdp</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x</span><span class="o">*</span><span class="n">rho</span><span class="p">)</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">x</span><span class="o">*</span><span class="n">rho</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">rdp_eps</span> <span class="o">=</span> <span class="n">alpha</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ys_gauss_rdp</span> <span class="o">=</span> <span class="p">[(</span><span class="n">x</span><span class="o">*</span><span class="n">rdp_eps</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">alpha</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">ys_moments</span> <span class="o">=</span> <span class="p">[</span><span class="mi">4</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">delta</span><span class="p">))</span><span class="o">/</span><span class="n">sigma</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xs</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_adv</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+Adv. Comp.&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_zcdp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+zCDP&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys_gauss_rdp</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Gaussian+RDP&quot;</span><span class="p">)</span>
<span class="c1">#plt.plot(xs, ys_moments, label=&quot;Moments Accountant&quot;)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Iterations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Epsilon&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ch8_16_0.png" src="../_images/ch8_16_0.png" />
</div>
</div>
<p>The first thing to note is that using sequential composition under either zCDP or RDP is <em>much</em> better than using advanced composition with <span class="math notranslate nohighlight">\((\epsilon, \delta)\)</span>-differential privacy. When building iterative algorithms with the Gaussian mechanism, these variants should always be used.</p>
<p>The second thing to note is the difference between zCDP (in orange) and RDP (in green). The <span class="math notranslate nohighlight">\(\epsilon\)</span> for RDP grows linearly in <span class="math notranslate nohighlight">\(k\)</span>, because we have fixed a value for <span class="math notranslate nohighlight">\(\alpha\)</span>. The <span class="math notranslate nohighlight">\(\epsilon\)</span> for zCDP is sublinear in <span class="math notranslate nohighlight">\(k\)</span>, since zCDP effectively considers many <span class="math notranslate nohighlight">\(\alpha\)</span>s. The two lines touch at some value of <span class="math notranslate nohighlight">\(k\)</span>, depending on the <span class="math notranslate nohighlight">\(\alpha\)</span> chosen for RDP (for <span class="math notranslate nohighlight">\(\alpha = 20\)</span>, they touch at roughly <span class="math notranslate nohighlight">\(k=300\)</span>).</p>
<p>The practial effect of this difference is that <span class="math notranslate nohighlight">\(\alpha\)</span> must be chosen carefully when using RDP in order to bound privacy cost as tightly as possible. This is usually easy to do, since algorithms are usually parameterized by <span class="math notranslate nohighlight">\(\alpha\)</span>; as a result, we can simply test multiple values of <span class="math notranslate nohighlight">\(\alpha\)</span> to see which one results in the smallest corresponding <span class="math notranslate nohighlight">\(\epsilon\)</span>. Since this test is <em>independent</em> of the data (it depends mainly on the privacy parameters we pick, and the number of iterations we want to run), we can test as many values of <span class="math notranslate nohighlight">\(\alpha\)</span> as we want without paying additional privacy cost. We only need to test a small range of values for <span class="math notranslate nohighlight">\(\alpha\)</span> - typically in the range between 2 and 100 - to find a minimum. This is the approach taken in most practical implementations, including Google’s privacy-preserving version of Tensorflow.</p>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="ch7.html" title="previous page">Local Sensitivity</a>
    <a class='right-next' id="next-link" href="ch9.html" title="next page">The Exponential Mechanism</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Joseph P. Near<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>